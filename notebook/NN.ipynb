{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03d0c265-e6c1-4f5a-861c-76bdf8e89d9e",
   "metadata": {},
   "source": [
    "# Neural Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "a39a42a9-e104-4e3d-a336-f1e5baa617f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# ユーザー数、アイテム数、評価値の範囲\n",
    "num_users = 50\n",
    "num_items = 50\n",
    "max_rating = 5\n",
    "min_rating = 1\n",
    "\n",
    "# データセットの生成\n",
    "ratings = np.random.randint(min_rating, max_rating+1, size=(num_users, num_items))\n",
    "ratings = (ratings-1)/4\n",
    "\n",
    "# ネットワークの定義\n",
    "class NCF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, factor_num=5, layers=[10,5]):\n",
    "        super(NCF, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.factor_num = factor_num\n",
    "        self.layers = layers\n",
    "\n",
    "        self.embedding_user = nn.Embedding(num_embeddings=self.num_users, embedding_dim=5)\n",
    "        self.embedding_item = nn.Embedding(num_embeddings=self.num_items, embedding_dim=5)\n",
    "\n",
    "        self.fc_layers = nn.ModuleList()\n",
    "        for idx, (in_size, out_size) in enumerate(zip(self.layers[:-1], self.layers[1:])):\n",
    "            self.fc_layers.append(nn.Linear(in_size, out_size))\n",
    "\n",
    "        self.affine_output = nn.Linear(in_features=self.layers[-1], out_features=1)\n",
    "        self.logistic = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, user_indices, item_indices):\n",
    "        user_embedding = self.embedding_user(user_indices)\n",
    "        item_embedding = self.embedding_item(item_indices)\n",
    "        vector = torch.cat([user_embedding, item_embedding], dim=-1)  # the concat latent vector\n",
    "        for idx, _ in enumerate(range(len(self.fc_layers))):\n",
    "            vector = self.fc_layers[idx](vector)\n",
    "            vector = nn.ReLU()(vector)\n",
    "        logits = self.affine_output(vector)\n",
    "        rating = self.logistic(logits)\n",
    "        return rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "4e337c5f-f571-4c00-b2f3-d2bb37aaf987",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NCF(num_users, num_items)\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "72375cff-8907-4a9a-b983-db557844c490",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "for epoch in range(30):\n",
    "    model.train() # Enable dropout (if have).\n",
    "    \n",
    "    epoch_loss = 0.0\n",
    "    for user_index in range(num_users):\n",
    "        for item_index in range(num_items):\n",
    "            rating = float(ratings[user_index, item_index])\n",
    "            label = torch.FloatTensor([[rating]])\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            user = torch.LongTensor([user_index])\n",
    "            item = torch.LongTensor([item_index])\n",
    "            prediction = model(user, item)\n",
    "            \n",
    "            loss = loss_function(prediction, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss+=loss.item()\n",
    "    \n",
    "    losses.append(epoch_loss)\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "9e1784ef-bdd8-4d9c-a922-831db3b35714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1729.9323657751083,\n",
       " 1729.5330923199654,\n",
       " 1729.1415237784386,\n",
       " 1728.7692486643791,\n",
       " 1728.3915739655495,\n",
       " 1727.9939889907837,\n",
       " 1727.603432893753,\n",
       " 1727.2323777079582,\n",
       " 1726.850794017315,\n",
       " 1726.4513570070267,\n",
       " 1726.0422974526882,\n",
       " 1725.6258172988892,\n",
       " 1725.1787912845612,\n",
       " 1724.7289662361145,\n",
       " 1724.2784088551998,\n",
       " 1723.8056592345238,\n",
       " 1723.3448340594769,\n",
       " 1722.8975209593773,\n",
       " 1722.478587925434,\n",
       " 1722.0650717020035,\n",
       " 1721.6422416567802,\n",
       " 1721.2343438267708,\n",
       " 1720.799686074257,\n",
       " 1720.3994975090027,\n",
       " 1719.9930233955383,\n",
       " 1719.5862289071083,\n",
       " 1719.1797151565552,\n",
       " 1718.7649176716805,\n",
       " 1718.3551274240017,\n",
       " 1717.9440604746342]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c401c1-42ce-47fd-afbb-2a1e117f508a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
